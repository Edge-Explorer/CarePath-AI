{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56e532a5-6df0-4585-8533-645cdb667b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import joblib\n",
    "import sqlite3\n",
    "import re\n",
    "from typing import TypedDict, Optional\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d654b54-6949-45e5-bf14-52d16e567376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from: ../notebooks/disease_model.pkl\n",
      "Model expects these features (in this order):\n",
      "['Disease', 'Fever', 'Cough', 'Fatigue', 'Difficulty Breathing', 'Age', 'Gender', 'Blood Pressure', 'Cholesterol Level']\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH=\"../notebooks/disease_model.pkl\"\n",
    "\n",
    "try:\n",
    "    model=joblib.load(MODEL_PATH)\n",
    "    print(\"Model loaded successfully from:\", MODEL_PATH)\n",
    "    print(\"Model expects these features (in this order):\")\n",
    "    print(list(model.feature_names_in_))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Model file not found at {MODEL_PATH}\")\n",
    "    print(\"Make sure you've run the first notebook and saved the model\")\n",
    "except AttributeError:\n",
    "    print(\"model.feature_names_in_ not available. Inspect training notebook for feature order.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b92b6e-d0f0-4f4e-821f-81fc07d019a6",
   "metadata": {},
   "source": [
    "### The formatter function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fffb0800-e84e-4a66-8fe7-5e79f134714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_symptoms(symptoms: dict):\n",
    "    \"\"\"\n",
    "    Reorders and fills missing features so input matches the model requirements.\n",
    "    \"\"\"\n",
    "    required_features = list(model.feature_names_in_)\n",
    "    formatted = {feature: symptoms.get(feature, 0) for feature in required_features}\n",
    "    return pd.DataFrame([formatted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13a07b21-a55f-4b70-8faf-b2d8c5039fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final features passed to model:\n",
      "   Disease  Fever  Cough  Fatigue  Difficulty Breathing  Age  Gender  \\\n",
      "0        0      1      0        1                     0   45       1   \n",
      "\n",
      "   Blood Pressure  Cholesterol Level  \n",
      "0             140                230  \n",
      "Predicted Outcome: 1\n"
     ]
    }
   ],
   "source": [
    "sample_symptoms = {\n",
    "    \"Disease\": 0,\n",
    "    \"Fever\": 1,\n",
    "    \"Cough\": 0,\n",
    "    \"Fatigue\": 1,\n",
    "    \"Difficulty Breathing\": 0,\n",
    "    \"Age\": 45,\n",
    "    \"Gender\": 1,\n",
    "    \"Blood Pressure\": 140,\n",
    "    \"Cholesterol Level\": 230\n",
    "}\n",
    "\n",
    "features = format_symptoms(sample_symptoms)\n",
    "print(\"Final features passed to model:\")\n",
    "print(features)\n",
    "\n",
    "prediction = model.predict(features)[0]\n",
    "print(\"Predicted Outcome:\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a515d5-2b27-48d6-85d4-6fe17fc751a6",
   "metadata": {},
   "source": [
    "### Initialize database with sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d97c990-fbc7-4b5d-b1f4-eda25762d835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_records table is ready.\n"
     ]
    }
   ],
   "source": [
    "def init_db(db_path=\"patient.db\"):\n",
    "    conn=sqlite3.connect(db_path)\n",
    "    cursor=conn.cursor()\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS patient_records(\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        symptoms TEXT,\n",
    "        prediction INTEGER,\n",
    "        reasoning TEXT,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "    \"\"\")\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM patient_records\")\n",
    "    count=cursor.fetchone()[0]\n",
    "        \n",
    "    \n",
    "    if count == 0:\n",
    "        # Add some sample records for testing\n",
    "        sample_records = [\n",
    "            (\"Fever: 1, Cough: 0, Fatigue: 1, Age: 45\", 1, \"Patient shows signs of flu-like symptoms with fever and fatigue\"),\n",
    "            (\"Fever: 0, Cough: 1, Fatigue: 0, Age: 30\", 0, \"Mild respiratory symptoms, likely common cold\"),\n",
    "            (\"Fever: 1, Cough: 1, Fatigue: 1, Age: 65\", 1, \"Multiple symptoms present, requires medical attention\")\n",
    "        ]\n",
    "        \n",
    "        cursor.executemany(\n",
    "            \"INSERT INTO patient_records (symptoms, prediction, reasoning) VALUES (?, ?, ?)\",\n",
    "            sample_records\n",
    "        )\n",
    "        print(\"Added sample records to database\")\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"patient_records table is ready.\")\n",
    "\n",
    "init_db(\"patient.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85e1d6ea-2450-4e26-bc09-1b23069ed23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-community faiss-cpu sentence-transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f74a30c9-b207-4d95-8554-51791bf5303a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 7 records from database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20308\\981870933.py:17: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore built with 7 past cases\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from langchain_community.vectorstores import FAISS\n",
    "    from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "    conn=sqlite3.connect(\"patient.db\")\n",
    "    df=pd.read_sql_query(\"SELECT id, symptoms, prediction, reasoning FROM patient_records\", conn)\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"Retrieved {len(df)} records from database\")\n",
    "\n",
    "    if len(df)>0:\n",
    "        df[\"case_text\"]=df.apply(\n",
    "            lambda row: f\"Symptoms: {row['symptoms']} | Prediction:{row['prediction']} | Reasoning{row['reasoning']}\",\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        embeddings=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        vectorstore=FAISS.from_texts(df[\"case_text\"].tolist(), embeddings)\n",
    "        print(f\"Vectorstore built with {len(df)} past cases\")\n",
    "    else:\n",
    "        vectorstore=None\n",
    "        print(\"No records found in database, vectorstore set to None\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"Import error:{e}\")\n",
    "    print(\"Please install required packages: pip install langchain-community faiss-cpu sentence-transformer\")\n",
    "    vectorstore=None\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error creating vectorstore:{e}\")\n",
    "    vectorstore=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3303d9c3-e91f-496d-9bad-5e95323ff948",
   "metadata": {},
   "source": [
    "### Define retrieval function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ad4e53f-b4ba-47d8-9478-63a3d0ede5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_node(state):\n",
    "    \"\"\"Retrieve similar cases from the vectorstore\"\"\"\n",
    "    if vectorstore is None:\n",
    "        state[\"retrieved_cases\"]=[]\n",
    "        return state\n",
    "\n",
    "    query=str(state[\"symptoms\"])\n",
    "\n",
    "    try:\n",
    "        results=vectorstore.similarity_search(query, k=3)\n",
    "        state[\"retrieved_cases\"]=[r.page_content for r in results]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during retrieval:{e}\")\n",
    "        state[\"retrieved_cases\"]=[]\n",
    "\n",
    "    return state    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ab25293-f7d3-4de3-8634-acae703451cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientState(TypedDict):\n",
    "    symptoms: dict\n",
    "    prediction: Optional[int]\n",
    "    reasoning: Optional[str]\n",
    "    retrieved_cases: Optional[list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f3df782-0344-4d70-b25d-17504f6ad819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_disease(state: PatientState) -> dict:\n",
    "    \"\"\"\n",
    "    Takes symptoms, formats them, predicts disease, and adds prediction to the state.\n",
    "    \"\"\"\n",
    "    symptoms = state[\"symptoms\"]\n",
    "    features = format_symptoms(symptoms)\n",
    "    \n",
    "    print(\"Features passed to the model:\", features.to_dict(orient=\"records\")[0])\n",
    "    \n",
    "    prediction = model.predict(features)[0]\n",
    "\n",
    "    state[\"prediction\"] = int(prediction)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5453803d-1e02-485f-bc9f-b69d4782db5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama LLM initialized successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from langchain_ollama import OllamaLLM\n",
    "    \n",
    "    llm = OllamaLLM(\n",
    "        model=\"mistral\",\n",
    "        streaming=False\n",
    "    )\n",
    "    ollama_available = True\n",
    "    print(\"Ollama LLM initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Ollama not available: {e}\")\n",
    "    print(\"Using fallback reasoning function\")\n",
    "    ollama_available = False\n",
    "\n",
    "def reasoning_node(state: dict):\n",
    "    \"\"\"Generate reasoning for the prediction\"\"\"\n",
    "    symptoms = state[\"symptoms\"]\n",
    "    prediction = state[\"prediction\"]\n",
    "    retrieved_text = \"\\n\".join(state.get(\"retrieved_cases\", []))\n",
    "    \n",
    "    if ollama_available:\n",
    "        # Use LLM for reasoning\n",
    "        prompt = f\"\"\"\n",
    "        You are a medical assistant.\n",
    "\n",
    "        Here are some similar past cases:\n",
    "        {retrieved_text}\n",
    "\n",
    "        Now, based on the symptoms: {symptoms} \n",
    "        and the prediction: {prediction},\n",
    "\n",
    "        Write a professional, short, readable explanation. \n",
    "        - Use point-wise format.\n",
    "        - Include a clear conclusion at the end.\n",
    "        - Keep sentences concise and natural.\n",
    "        - Add relevant emojis for readability.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            reasoning_text = llm.invoke(prompt)\n",
    "            # Clean up the text\n",
    "            reasoning_text = re.sub(r'\\b(\\w+)\\s+\\1\\b', r'\\1', reasoning_text)\n",
    "            reasoning_text = re.sub(r'\\s+([,.;:])', r'\\1', reasoning_text)\n",
    "            reasoning_text = re.sub(r'\\n+', '\\n', reasoning_text).strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error with LLM reasoning: {e}\")\n",
    "            reasoning_text = generate_fallback_reasoning(symptoms, prediction)\n",
    "    else:\n",
    "        # Fallback reasoning\n",
    "        reasoning_text = generate_fallback_reasoning(symptoms, prediction)\n",
    "    \n",
    "    state[\"reasoning\"] = reasoning_text\n",
    "    return state\n",
    "\n",
    "def generate_fallback_reasoning(symptoms, prediction):\n",
    "    \"\"\"Generate basic reasoning when LLM is not available\"\"\"\n",
    "    outcome = \"Positive\" if prediction == 1 else \"Negative\"\n",
    "    \n",
    "    # Extract key symptoms\n",
    "    key_symptoms = []\n",
    "    if symptoms.get(\"Fever\", 0) == 1:\n",
    "        key_symptoms.append(\"fever\")\n",
    "    if symptoms.get(\"Cough\", 0) == 1:\n",
    "        key_symptoms.append(\"cough\")\n",
    "    if symptoms.get(\"Fatigue\", 0) == 1:\n",
    "        key_symptoms.append(\"fatigue\")\n",
    "    if symptoms.get(\"Difficulty Breathing\", 0) == 1:\n",
    "        key_symptoms.append(\"difficulty breathing\")\n",
    "    \n",
    "    reasoning = f\"\"\"\n",
    "    Analysis Summary:\n",
    "    • Patient Age: {symptoms.get('Age', 'N/A')} years\n",
    "    • Key Symptoms Present: {', '.join(key_symptoms) if key_symptoms else 'None reported'}\n",
    "    • Prediction: {outcome}\n",
    "    \n",
    "    Reasoning:\n",
    "    • Based on the symptom profile and patient demographics\n",
    "    • The model indicates a {outcome.lower()} outcome\n",
    "    • {\"Multiple symptoms suggest medical attention may be needed\" if prediction == 1 else \"Symptoms appear mild based on current assessment\"}\n",
    "    \n",
    "    Note: This is an automated assessment. Please consult healthcare professionals for proper medical advice.\n",
    "    \"\"\"\n",
    "    \n",
    "    return reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3acbf3b0-2f7f-477b-b788-1280a1588ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph workflow created successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from langgraph.graph import StateGraph\n",
    "    \n",
    "    # Build the graph\n",
    "    builder = StateGraph(PatientState)\n",
    "    builder.add_node(\"predict\", predict_disease)\n",
    "    builder.add_node(\"retrieve\", retrieve_node)\n",
    "    builder.add_node(\"reasoning\", reasoning_node)\n",
    "    \n",
    "    # Add edges\n",
    "    builder.add_edge(\"predict\", \"retrieve\")\n",
    "    builder.add_edge(\"retrieve\", \"reasoning\")\n",
    "    \n",
    "    # Set entry point\n",
    "    builder.set_entry_point(\"predict\")\n",
    "    app = builder.compile()\n",
    "    \n",
    "    print(\"LangGraph workflow created successfully\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"LangGraph not available: {e}\")\n",
    "    print(\"Please install: pip install langgraph\")\n",
    "    app = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e1fe215-87c7-4763-8ac7-b939fc5db921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features passed to the model: {'Disease': 0, 'Fever': 1, 'Cough': 0, 'Fatigue': 1, 'Difficulty Breathing': 0, 'Age': 45, 'Gender': 1, 'Blood Pressure': 140, 'Cholesterol Level': 230}\n",
      "\n",
      "==================================================\n",
      "WORKFLOW RESULTS\n",
      "==================================================\n",
      "Symptoms: {'Disease': 0, 'Fever': 1, 'Cough': 0, 'Fatigue': 1, 'Difficulty Breathing': 0, 'Age': 45, 'Gender': 1, 'Blood Pressure': 140, 'Cholesterol Level': 230}\n",
      "Prediction: 1\n",
      "Retrieved Cases: 3\n",
      "\n",
      "Reasoning:\n",
      "**Medical Assessment 🏥**\n",
      "• **Fever**: Present (1), indicating potential underlying condition 🔥\n",
      "• **Cough**: Absent (0), reducing likelihood of respiratory infection 🤧\n",
      "• **Fatigue**: Reported (1), suggesting possible underlying cause requiring medical attention 😴\n",
      "• **Difficulty Breathing**: Not observed (0), reassuring but not eliminating other possibilities 👅\n",
      "• **Age**: 45, within normal range for this profile 👵\n",
      "• **Gender**: Female (1), typical for this demographic 🚺\n",
      "• **Blood Pressure**: 140 mmHg, slightly elevated but not critically high 💧\n",
      "• **Cholesterol Level**: 230 mg/dL, borderline high but not alarmingly so 🥖\n",
      "**Conclusion:** Given the combination of symptoms, we predict that medical attention is required ⚠️. A thorough examination and laboratory tests are recommended to determine the underlying cause of the fever and fatigue 💡.\n",
      "**Recommendations:**\n",
      "1. Schedule an appointment with a healthcare provider for further evaluation.\n",
      "2. Complete a comprehensive physical exam to assess overall health status.\n",
      "3. Conduct blood tests to rule out underlying conditions, such as infections or autoimmune disorders.\n",
      "4. Consider additional testing, such as chest X-rays or lung function tests, if respiratory issues are suspected 💊🏥.\n"
     ]
    }
   ],
   "source": [
    "if app is not None:\n",
    "    sample_state: PatientState = {\n",
    "        \"symptoms\": {\n",
    "            \"Disease\": 0,\n",
    "            \"Fever\": 1,\n",
    "            \"Cough\": 0,\n",
    "            \"Fatigue\": 1,\n",
    "            \"Difficulty Breathing\": 0,\n",
    "            \"Age\": 45,\n",
    "            \"Gender\": 1,\n",
    "            \"Blood Pressure\": 140,\n",
    "            \"Cholesterol Level\": 230\n",
    "        },\n",
    "        \"prediction\": None,\n",
    "        \"reasoning\": None,\n",
    "        \"retrieved_cases\": None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        output = app.invoke(sample_state)\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"WORKFLOW RESULTS\")\n",
    "        print(\"=\"*50)\n",
    "        print(\"Symptoms:\", output[\"symptoms\"])\n",
    "        print(\"Prediction:\", output[\"prediction\"])\n",
    "        print(\"Retrieved Cases:\", len(output.get(\"retrieved_cases\", [])))\n",
    "        print(\"\\nReasoning:\")\n",
    "        print(output[\"reasoning\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Error running workflow: {e}\")\n",
    "else:\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"MANUAL TESTING (without LangGraph)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Test each component manually\n",
    "    test_state = {\n",
    "        \"symptoms\": sample_symptoms,\n",
    "        \"prediction\": None,\n",
    "        \"reasoning\": None,\n",
    "        \"retrieved_cases\": None\n",
    "    }\n",
    "    \n",
    "    # Step 1: Predict\n",
    "    test_state = predict_disease(test_state)\n",
    "    print(\"After prediction:\", test_state[\"prediction\"])\n",
    "    \n",
    "    # Step 2: Retrieve\n",
    "    test_state = retrieve_node(test_state)\n",
    "    print(\"Retrieved cases:\", len(test_state.get(\"retrieved_cases\", [])))\n",
    "    \n",
    "    # Step 3: Reasoning\n",
    "    test_state = reasoning_node(test_state)\n",
    "    print(\"\\nFinal Reasoning:\")\n",
    "    print(test_state[\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2733ed1-e2d8-443f-a92b-3cbbf9b08b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record saved to database with ID: 8\n",
      "\n",
      "Notebook execution completed!\n"
     ]
    }
   ],
   "source": [
    "def save_prediction_to_db(symptoms_dict, prediction, reasoning, db_path=\"patient.db\"):\n",
    "    \"\"\"Save the prediction results to database\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    symptoms_str = str(symptoms_dict)\n",
    "    \n",
    "    cursor.execute(\n",
    "        \"INSERT INTO patient_records (symptoms, prediction, reasoning) VALUES (?, ?, ?)\",\n",
    "        (symptoms_str, prediction, reasoning)\n",
    "    )\n",
    "    \n",
    "    conn.commit()\n",
    "    record_id = cursor.lastrowid\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"Record saved to database with ID: {record_id}\")\n",
    "    return record_id\n",
    "\n",
    "# Test saving the prediction\n",
    "if 'output' in locals() and output.get(\"prediction\") is not None:\n",
    "    save_prediction_to_db(\n",
    "        output[\"symptoms\"], \n",
    "        output[\"prediction\"], \n",
    "        output[\"reasoning\"]\n",
    "    )\n",
    "else:\n",
    "    print(\"No prediction to save\")\n",
    "\n",
    "print(\"\\nNotebook execution completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbafdc4-250f-46de-82bc-14fce2b0217d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
